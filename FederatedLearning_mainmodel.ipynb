{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following notebook was written by BM22BTECH11004 for preprocessing the PTBXL dataset and running main models on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "import time\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data from dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/bmi-lab/Downloads/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3'\n",
    "\n",
    "ptbxl_df = pd.read_csv(os.path.join(DATA_PATH, 'ptbxl_database.csv'))\n",
    "scp_statements = pd.read_csv(os.path.join(DATA_PATH, 'scp_statements.csv'), index_col=0)\n",
    "\n",
    "diagnostic_scps = scp_statements[scp_statements['diagnostic'] == 1].index.values\n",
    "\n",
    "scp_to_superclass = scp_statements['diagnostic_class'].to_dict()\n",
    "scp_to_subclass = scp_statements['diagnostic_subclass'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbxl_df['scp_codes'] = ptbxl_df['scp_codes'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_diagnostic_labels(df, scp_codes, scp_to_agg):\n",
    "    df = df.copy()\n",
    "    def aggregate_labels(scp_codes_dict):\n",
    "        labels = set()\n",
    "        for code in scp_codes_dict.keys():\n",
    "            if code in scp_codes:\n",
    "                label = scp_to_agg.get(code)\n",
    "                if label:\n",
    "                    labels.add(label)\n",
    "        return list(labels)\n",
    "    df['diagnostic_labels'] = df['scp_codes'].apply(aggregate_labels)\n",
    "    return df\n",
    "\n",
    "ptbxl_df = aggregate_diagnostic_labels(ptbxl_df, diagnostic_scps, scp_to_superclass)\n",
    "ptbxl_df = ptbxl_df.rename(columns={'diagnostic_labels': 'superclass_labels'})\n",
    "\n",
    "ptbxl_df = aggregate_diagnostic_labels(ptbxl_df, diagnostic_scps, scp_to_subclass)\n",
    "ptbxl_df = ptbxl_df.rename(columns={'diagnostic_labels': 'subclass_labels'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbxl_df = ptbxl_df[ptbxl_df['superclass_labels'].map(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = ptbxl_df[ptbxl_df.strat_fold <= 8]\n",
    "val_df = ptbxl_df[ptbxl_df.strat_fold == 9]\n",
    "test_df = ptbxl_df[ptbxl_df.strat_fold == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df, sampling_rate, data_path):\n",
    "    data = []\n",
    "    if sampling_rate == 100:\n",
    "        filenames = df['filename_lr'].values\n",
    "    else:\n",
    "        filenames = df['filename_hr'].values\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(data_path, filename)\n",
    "        signals, _ = wfdb.rdsamp(file_path)\n",
    "        data.append(signals)\n",
    "    return np.array(data)\n",
    "\n",
    "X_train = load_data(train_df, sampling_rate=100, data_path=DATA_PATH)\n",
    "X_val = load_data(val_df, sampling_rate=100, data_path=DATA_PATH)\n",
    "X_test = load_data(test_df, sampling_rate=100, data_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_super = train_df['superclass_labels'].values\n",
    "val_labels_super = val_df['superclass_labels'].values\n",
    "test_labels_super = test_df['superclass_labels'].values\n",
    "\n",
    "mlb_super = MultiLabelBinarizer()\n",
    "y_train_super = mlb_super.fit_transform(train_labels_super)\n",
    "y_val_super = mlb_super.transform(val_labels_super)\n",
    "y_test_super = mlb_super.transform(test_labels_super)\n",
    "classes_super = mlb_super.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_sub = train_df['subclass_labels'].values\n",
    "val_labels_sub = val_df['subclass_labels'].values\n",
    "test_labels_sub = test_df['subclass_labels'].values\n",
    "\n",
    "mlb_sub = MultiLabelBinarizer()\n",
    "y_train_sub = mlb_sub.fit_transform(train_labels_sub)\n",
    "y_val_sub = mlb_sub.transform(val_labels_sub)\n",
    "y_test_sub = mlb_sub.transform(test_labels_sub)\n",
    "classes_sub = mlb_sub.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data_per_channel(X):\n",
    "    X = np.transpose(X, (0, 2, 1))\n",
    "    mean = np.mean(X, axis=(0, 2), keepdims=True)\n",
    "    std = np.std(X, axis=(0, 2), keepdims=True)\n",
    "    X = (X - mean) / std\n",
    "    X = np.transpose(X, (0, 2, 1))\n",
    "    return X\n",
    "\n",
    "X_train = normalize_data_per_channel(X_train)\n",
    "X_val = normalize_data_per_channel(X_val)\n",
    "X_test = normalize_data_per_channel(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts_super = np.sum(y_train_super, axis=0)\n",
    "total_samples_super = y_train_super.shape[0]\n",
    "\n",
    "class_weight_super = {}\n",
    "for i, count in enumerate(class_counts_super):\n",
    "    class_weight_super[i] = total_samples_super / (len(class_counts_super) * count)\n",
    "\n",
    "class_counts_sub = np.sum(y_train_sub, axis=0)\n",
    "total_samples_sub = y_train_sub.shape[0]\n",
    "\n",
    "class_weight_sub = {}\n",
    "for i, count in enumerate(class_counts_sub):\n",
    "    class_weight_sub[i] = total_samples_sub / (len(class_counts_sub) * count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes_super = y_train_super.shape[1]\n",
    "class_totals = np.sum(y_train_super, axis=0)\n",
    "class_weights = class_totals.max() / class_totals\n",
    "weights_array = np.array(class_weights, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes_sub = y_train_sub.shape[1]\n",
    "class_totals_sub = np.sum(y_train_sub, axis=0)\n",
    "class_weights_sub = class_totals_sub.max() / class_totals_sub\n",
    "weights_array_sub = np.array(class_weights_sub, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_super = y_train_super.astype(np.float32)\n",
    "y_val_super = y_val_super.astype(np.float32)\n",
    "y_test_super = y_test_super.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Entropy and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def weighted_binary_crossentropy(weights):\n",
    "    def loss(y_true, y_pred):\n",
    "        weights_cast = K.cast(weights, y_pred.dtype)\n",
    "        y_true = K.cast(y_true, y_pred.dtype)\n",
    "        \n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        weight_vector = y_true * weights_cast + (1 - y_true)\n",
    "        weighted_bce = weight_vector * bce\n",
    "        return K.mean(weighted_bce)\n",
    "    return loss\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred = K.round(y_pred)\n",
    "    \n",
    "    tp = K.sum(y_true * y_pred, axis=0)\n",
    "    fp = K.sum((1 - y_true) * y_pred, axis=0)\n",
    "    fn = K.sum(y_true * (1 - y_pred), axis=0)\n",
    "\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv1D(64, kernel_size=7, padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv1D(128, kernel_size=5, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv1D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv1D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_resnet_model(input_shape, num_classes):\n",
    "#     inputs = layers.Input(shape=input_shape)\n",
    "#     x = layers.Conv1D(64, kernel_size=7, strides=2, padding='same')(inputs)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Activation('relu')(x)\n",
    "#     x = layers.MaxPooling1D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "#     previous_filters = x.shape[-1]\n",
    "#     for filters in [64, 128, 256]:\n",
    "#         x_shortcut = x\n",
    "#         strides = 1\n",
    "#         if previous_filters != filters:\n",
    "#             strides = 2\n",
    "\n",
    "#         x = layers.Conv1D(filters, kernel_size=3, strides=strides, padding='same')(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "#         x = layers.Activation('relu')(x)\n",
    "#         x = layers.Conv1D(filters, kernel_size=3, padding='same')(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "        \n",
    "#         if previous_filters != filters or strides != 1:\n",
    "#             x_shortcut = layers.Conv1D(filters, kernel_size=1, strides=strides, padding='same')(x_shortcut)\n",
    "#             x_shortcut = layers.BatchNormalization()(x_shortcut)\n",
    "        \n",
    "#         x = layers.Add()([x, x_shortcut])\n",
    "#         x = layers.Activation('relu')(x)\n",
    "#         previous_filters = filters\n",
    "#     x = layers.GlobalAveragePooling1D()(x)\n",
    "#     outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "#     model = models.Model(inputs, outputs)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block_1d(x, filters, kernel_size=3, strides=1, downsample=False):\n",
    "    shortcut = x\n",
    "    \n",
    "    x = layers.Conv1D(filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv1D(filters, kernel_size=kernel_size, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    if downsample or shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv1D(filters, kernel_size=1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def create_resnet_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(64, kernel_size=7, strides=2, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=3, strides=2, padding='same')(x)\n",
    "    layers_filters = [64, 128, 256, 512]\n",
    "    layers_blocks = [3, 4, 6, 3]\n",
    "\n",
    "    for filters, num_blocks in zip(layers_filters, layers_blocks):\n",
    "        for i in range(num_blocks):\n",
    "            if i == 0 and filters != x.shape[-1]:\n",
    "                x = residual_block_1d(x, filters, strides=2, downsample=True)\n",
    "            else:\n",
    "                x = residual_block_1d(x, filters)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "def create_vit_model(input_shape, num_classes):\n",
    "    patch_size = 10 \n",
    "    num_patches = input_shape[0] // patch_size\n",
    "    projection_dim = 64\n",
    "    num_heads = 4\n",
    "    transformer_layers = 8\n",
    "    mlp_head_units = [256, 128]\n",
    "    dropout_rate = 0.1\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Reshape((num_patches, patch_size * input_shape[1]))(inputs)\n",
    "    x = layers.Dense(units=projection_dim)(x)\n",
    "    positions = tf.range(start=0, limit=num_patches, delta=1)\n",
    "    position_embedding = layers.Embedding(input_dim=num_patches, output_dim=projection_dim)\n",
    "    x = x + position_embedding(positions)\n",
    "    for _ in range(transformer_layers):\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=dropout_rate\n",
    "        )(x1, x1)\n",
    "        x2 = layers.Add()([attention_output, x])\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = mlp(x3, hidden_units=[projection_dim * 2, projection_dim], dropout_rate=dropout_rate)\n",
    "        x = layers.Add()([x3, x2])\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, class_weight, batch_size=64, epochs=25):\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', macro_f1]\n",
    "    )\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluating Models without CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 16:09:31.270097: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-19 16:09:31.549533: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-19 16:09:31.552110: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-19 16:09:31.555656: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-19 16:09:31.559368: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-19 16:09:31.561785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-19 16:09:31.563359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-19 16:09:31.664691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-19 16:09:31.665914: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-19 16:09:31.667141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-19 16:09:31.668300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13813 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 16:09:33.322857: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8907\n",
      "2024-11-19 16:09:34.093169: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-11-19 16:09:34.191615: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x73d9f8042e20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-11-19 16:09:34.191677: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 4080, Compute Capability 8.9\n",
      "2024-11-19 16:09:34.242857: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-19 16:09:34.547318: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 5s 7ms/step - loss: 0.2797 - accuracy: 0.6384 - macro_f1: 0.6584 - val_loss: 0.3618 - val_accuracy: 0.6342 - val_macro_f1: 0.6274 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.2422 - accuracy: 0.6853 - macro_f1: 0.7098 - val_loss: 0.3546 - val_accuracy: 0.6696 - val_macro_f1: 0.6617 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.2281 - accuracy: 0.7005 - macro_f1: 0.7294 - val_loss: 0.3061 - val_accuracy: 0.6873 - val_macro_f1: 0.7062 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 0.2208 - accuracy: 0.7081 - macro_f1: 0.7385 - val_loss: 0.3125 - val_accuracy: 0.6752 - val_macro_f1: 0.6934 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.2149 - accuracy: 0.7142 - macro_f1: 0.7469 - val_loss: 0.3087 - val_accuracy: 0.6887 - val_macro_f1: 0.7001 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.2069 - accuracy: 0.7251 - macro_f1: 0.7559 - val_loss: 0.2876 - val_accuracy: 0.6952 - val_macro_f1: 0.7046 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 0.2026 - accuracy: 0.7251 - macro_f1: 0.7600 - val_loss: 0.2969 - val_accuracy: 0.6883 - val_macro_f1: 0.7184 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 0.1972 - accuracy: 0.7325 - macro_f1: 0.7684 - val_loss: 0.2779 - val_accuracy: 0.7213 - val_macro_f1: 0.7196 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.1922 - accuracy: 0.7367 - macro_f1: 0.7727 - val_loss: 0.2882 - val_accuracy: 0.7018 - val_macro_f1: 0.7139 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.1873 - accuracy: 0.7394 - macro_f1: 0.7805 - val_loss: 0.2828 - val_accuracy: 0.6929 - val_macro_f1: 0.7217 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.1846 - accuracy: 0.7413 - macro_f1: 0.7826 - val_loss: 0.2932 - val_accuracy: 0.7008 - val_macro_f1: 0.7212 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.1789 - accuracy: 0.7485 - macro_f1: 0.7915 - val_loss: 0.2899 - val_accuracy: 0.6985 - val_macro_f1: 0.7207 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.1721 - accuracy: 0.7515 - macro_f1: 0.7963 - val_loss: 0.3178 - val_accuracy: 0.6873 - val_macro_f1: 0.7195 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.1461 - accuracy: 0.7779 - macro_f1: 0.8292 - val_loss: 0.2813 - val_accuracy: 0.7046 - val_macro_f1: 0.7278 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.1363 - accuracy: 0.7858 - macro_f1: 0.8422 - val_loss: 0.2836 - val_accuracy: 0.7088 - val_macro_f1: 0.7249 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 0.1308 - accuracy: 0.7876 - macro_f1: 0.8482 - val_loss: 0.2915 - val_accuracy: 0.7106 - val_macro_f1: 0.7288 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.1264 - accuracy: 0.7909 - macro_f1: 0.8531 - val_loss: 0.2960 - val_accuracy: 0.7097 - val_macro_f1: 0.7169 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.1236 - accuracy: 0.7944 - macro_f1: 0.8565 - val_loss: 0.2991 - val_accuracy: 0.7130 - val_macro_f1: 0.7257 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x73dc79970be0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "num_classes_super = y_train_super.shape[1]\n",
    "\n",
    "cnn_super_model = create_cnn_model(input_shape, num_classes_super)\n",
    "train_model(cnn_super_model, X_train, y_train_super, X_val, y_val_super, class_weight_super)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "267/267 [==============================] - 14s 22ms/step - loss: 0.3015 - accuracy: 0.6271 - macro_f1: 0.6294 - val_loss: 0.6704 - val_accuracy: 0.3882 - val_macro_f1: 0.4309 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.2545 - accuracy: 0.6802 - macro_f1: 0.6948 - val_loss: 0.3448 - val_accuracy: 0.6561 - val_macro_f1: 0.6679 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.2375 - accuracy: 0.6924 - macro_f1: 0.7167 - val_loss: 0.4898 - val_accuracy: 0.5415 - val_macro_f1: 0.6120 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.2312 - accuracy: 0.6977 - macro_f1: 0.7230 - val_loss: 0.3757 - val_accuracy: 0.6789 - val_macro_f1: 0.6919 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.2215 - accuracy: 0.7141 - macro_f1: 0.7379 - val_loss: 0.3218 - val_accuracy: 0.6664 - val_macro_f1: 0.6708 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.2150 - accuracy: 0.7179 - macro_f1: 0.7463 - val_loss: 0.4310 - val_accuracy: 0.6300 - val_macro_f1: 0.6252 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.2079 - accuracy: 0.7232 - macro_f1: 0.7532 - val_loss: 0.4028 - val_accuracy: 0.6575 - val_macro_f1: 0.6766 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.2035 - accuracy: 0.7249 - macro_f1: 0.7587 - val_loss: 0.3586 - val_accuracy: 0.6482 - val_macro_f1: 0.6775 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1989 - accuracy: 0.7321 - macro_f1: 0.7657 - val_loss: 0.3865 - val_accuracy: 0.6757 - val_macro_f1: 0.6988 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1921 - accuracy: 0.7352 - macro_f1: 0.7747 - val_loss: 0.3863 - val_accuracy: 0.6994 - val_macro_f1: 0.6853 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.1601 - accuracy: 0.7643 - macro_f1: 0.8139 - val_loss: 0.2795 - val_accuracy: 0.6906 - val_macro_f1: 0.7198 - lr: 1.0000e-04\n",
      "Epoch 12/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1500 - accuracy: 0.7735 - macro_f1: 0.8255 - val_loss: 0.2934 - val_accuracy: 0.6966 - val_macro_f1: 0.7220 - lr: 1.0000e-04\n",
      "Epoch 13/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1412 - accuracy: 0.7787 - macro_f1: 0.8370 - val_loss: 0.3077 - val_accuracy: 0.6971 - val_macro_f1: 0.7099 - lr: 1.0000e-04\n",
      "Epoch 14/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1319 - accuracy: 0.7860 - macro_f1: 0.8491 - val_loss: 0.3250 - val_accuracy: 0.6971 - val_macro_f1: 0.7127 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1221 - accuracy: 0.7912 - macro_f1: 0.8568 - val_loss: 0.3584 - val_accuracy: 0.6985 - val_macro_f1: 0.6994 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.1073 - accuracy: 0.7955 - macro_f1: 0.8770 - val_loss: 0.3691 - val_accuracy: 0.6892 - val_macro_f1: 0.7060 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0825 - accuracy: 0.8149 - macro_f1: 0.9066 - val_loss: 0.3851 - val_accuracy: 0.6813 - val_macro_f1: 0.7065 - lr: 1.0000e-05\n",
      "Epoch 18/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0751 - accuracy: 0.8156 - macro_f1: 0.9165 - val_loss: 0.4284 - val_accuracy: 0.6799 - val_macro_f1: 0.7076 - lr: 1.0000e-05\n",
      "Epoch 19/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0697 - accuracy: 0.8191 - macro_f1: 0.9214 - val_loss: 0.4712 - val_accuracy: 0.6808 - val_macro_f1: 0.6969 - lr: 1.0000e-05\n",
      "Epoch 20/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0672 - accuracy: 0.8210 - macro_f1: 0.9255 - val_loss: 0.4898 - val_accuracy: 0.6766 - val_macro_f1: 0.6957 - lr: 1.0000e-05\n",
      "Epoch 21/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0633 - accuracy: 0.8222 - macro_f1: 0.9289 - val_loss: 0.5047 - val_accuracy: 0.6738 - val_macro_f1: 0.6958 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x73dc60d4cb50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_super_model = create_resnet_model(input_shape, num_classes_super)\n",
    "train_model(resnet_super_model, X_train, y_train_super, X_val, y_val_super, class_weight_super)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "267/267 [==============================] - 13s 20ms/step - loss: 0.3824 - accuracy: 0.4987 - macro_f1: 0.4738 - val_loss: 0.3772 - val_accuracy: 0.5718 - val_macro_f1: 0.5947 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.2926 - accuracy: 0.6282 - macro_f1: 0.6302 - val_loss: 0.3544 - val_accuracy: 0.6398 - val_macro_f1: 0.5986 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.2587 - accuracy: 0.6657 - macro_f1: 0.6803 - val_loss: 0.3343 - val_accuracy: 0.6654 - val_macro_f1: 0.6820 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.2377 - accuracy: 0.6905 - macro_f1: 0.7151 - val_loss: 0.3849 - val_accuracy: 0.6454 - val_macro_f1: 0.6654 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.2215 - accuracy: 0.7009 - macro_f1: 0.7318 - val_loss: 0.3230 - val_accuracy: 0.6827 - val_macro_f1: 0.6708 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.2084 - accuracy: 0.7177 - macro_f1: 0.7501 - val_loss: 0.3321 - val_accuracy: 0.6705 - val_macro_f1: 0.6537 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.1958 - accuracy: 0.7273 - macro_f1: 0.7657 - val_loss: 0.3942 - val_accuracy: 0.5979 - val_macro_f1: 0.6445 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1811 - accuracy: 0.7389 - macro_f1: 0.7845 - val_loss: 0.3455 - val_accuracy: 0.6682 - val_macro_f1: 0.6650 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1682 - accuracy: 0.7528 - macro_f1: 0.8031 - val_loss: 0.3625 - val_accuracy: 0.6692 - val_macro_f1: 0.6685 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.1560 - accuracy: 0.7582 - macro_f1: 0.8185 - val_loss: 0.3711 - val_accuracy: 0.6482 - val_macro_f1: 0.6737 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1099 - accuracy: 0.7987 - macro_f1: 0.8785 - val_loss: 0.4045 - val_accuracy: 0.6780 - val_macro_f1: 0.6832 - lr: 1.0000e-04\n",
      "Epoch 12/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0939 - accuracy: 0.8097 - macro_f1: 0.8981 - val_loss: 0.4232 - val_accuracy: 0.6719 - val_macro_f1: 0.6842 - lr: 1.0000e-04\n",
      "Epoch 13/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0876 - accuracy: 0.8166 - macro_f1: 0.9032 - val_loss: 0.4394 - val_accuracy: 0.6696 - val_macro_f1: 0.6807 - lr: 1.0000e-04\n",
      "Epoch 14/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0817 - accuracy: 0.8217 - macro_f1: 0.9114 - val_loss: 0.4447 - val_accuracy: 0.6780 - val_macro_f1: 0.6820 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0774 - accuracy: 0.8238 - macro_f1: 0.9167 - val_loss: 0.4665 - val_accuracy: 0.6673 - val_macro_f1: 0.6758 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x73dbe4067df0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_super_model = create_vit_model(input_shape, num_classes_super)\n",
    "train_model(vit_super_model, X_train, y_train_super, X_val, y_val_super, class_weight_super)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "267/267 [==============================] - 3s 7ms/step - loss: 0.1084 - accuracy: 0.3936 - macro_f1: 0.1386 - val_loss: 0.1403 - val_accuracy: 0.5303 - val_macro_f1: 0.1263 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0899 - accuracy: 0.4710 - macro_f1: 0.1888 - val_loss: 0.1414 - val_accuracy: 0.5065 - val_macro_f1: 0.1767 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0840 - accuracy: 0.4974 - macro_f1: 0.2213 - val_loss: 0.1536 - val_accuracy: 0.4623 - val_macro_f1: 0.1564 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0775 - accuracy: 0.5103 - macro_f1: 0.2367 - val_loss: 0.1536 - val_accuracy: 0.3975 - val_macro_f1: 0.2138 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 0.0703 - accuracy: 0.5210 - macro_f1: 0.2643 - val_loss: 0.1270 - val_accuracy: 0.5163 - val_macro_f1: 0.2207 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0685 - accuracy: 0.5353 - macro_f1: 0.2711 - val_loss: 0.1256 - val_accuracy: 0.5410 - val_macro_f1: 0.2326 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0631 - accuracy: 0.5427 - macro_f1: 0.2945 - val_loss: 0.1241 - val_accuracy: 0.5377 - val_macro_f1: 0.2483 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0589 - accuracy: 0.5555 - macro_f1: 0.3134 - val_loss: 0.1118 - val_accuracy: 0.5722 - val_macro_f1: 0.2702 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0568 - accuracy: 0.5698 - macro_f1: 0.3240 - val_loss: 0.1112 - val_accuracy: 0.5760 - val_macro_f1: 0.2828 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0554 - accuracy: 0.5666 - macro_f1: 0.3287 - val_loss: 0.1210 - val_accuracy: 0.5485 - val_macro_f1: 0.2559 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 0.0539 - accuracy: 0.5767 - macro_f1: 0.3356 - val_loss: 0.1128 - val_accuracy: 0.5871 - val_macro_f1: 0.2752 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0508 - accuracy: 0.5867 - macro_f1: 0.3482 - val_loss: 0.1149 - val_accuracy: 0.5764 - val_macro_f1: 0.2623 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0521 - accuracy: 0.5869 - macro_f1: 0.3492 - val_loss: 0.1141 - val_accuracy: 0.5718 - val_macro_f1: 0.2901 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0493 - accuracy: 0.5957 - macro_f1: 0.3662 - val_loss: 0.1120 - val_accuracy: 0.5825 - val_macro_f1: 0.2956 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0422 - accuracy: 0.6263 - macro_f1: 0.3865 - val_loss: 0.1048 - val_accuracy: 0.6048 - val_macro_f1: 0.3053 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0406 - accuracy: 0.6319 - macro_f1: 0.3970 - val_loss: 0.1046 - val_accuracy: 0.6072 - val_macro_f1: 0.3072 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0398 - accuracy: 0.6351 - macro_f1: 0.4045 - val_loss: 0.1054 - val_accuracy: 0.6039 - val_macro_f1: 0.3075 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0391 - accuracy: 0.6330 - macro_f1: 0.4068 - val_loss: 0.1049 - val_accuracy: 0.6114 - val_macro_f1: 0.3069 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0386 - accuracy: 0.6379 - macro_f1: 0.4086 - val_loss: 0.1052 - val_accuracy: 0.6109 - val_macro_f1: 0.3057 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0381 - accuracy: 0.6391 - macro_f1: 0.4139 - val_loss: 0.1046 - val_accuracy: 0.6132 - val_macro_f1: 0.3122 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0372 - accuracy: 0.6434 - macro_f1: 0.4156 - val_loss: 0.1051 - val_accuracy: 0.6081 - val_macro_f1: 0.3131 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0364 - accuracy: 0.6470 - macro_f1: 0.4177 - val_loss: 0.1043 - val_accuracy: 0.6072 - val_macro_f1: 0.3130 - lr: 1.0000e-05\n",
      "Epoch 23/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0360 - accuracy: 0.6465 - macro_f1: 0.4243 - val_loss: 0.1049 - val_accuracy: 0.6090 - val_macro_f1: 0.3145 - lr: 1.0000e-05\n",
      "Epoch 24/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0362 - accuracy: 0.6480 - macro_f1: 0.4250 - val_loss: 0.1045 - val_accuracy: 0.6081 - val_macro_f1: 0.3172 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "267/267 [==============================] - 2s 6ms/step - loss: 0.0361 - accuracy: 0.6496 - macro_f1: 0.4252 - val_loss: 0.1052 - val_accuracy: 0.6104 - val_macro_f1: 0.3076 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x73dbccd2f070>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes_sub = y_train_sub.shape[1]\n",
    "cnn_sub_model = create_cnn_model(input_shape, num_classes_sub)\n",
    "train_model(cnn_sub_model, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "267/267 [==============================] - 14s 21ms/step - loss: 0.1181 - accuracy: 0.3439 - macro_f1: 0.0673 - val_loss: 0.1689 - val_accuracy: 0.4264 - val_macro_f1: 0.1547 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.1026 - accuracy: 0.4255 - macro_f1: 0.1100 - val_loss: 0.3509 - val_accuracy: 0.0974 - val_macro_f1: 0.0624 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0921 - accuracy: 0.4473 - macro_f1: 0.1355 - val_loss: 0.1577 - val_accuracy: 0.4567 - val_macro_f1: 0.1011 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0856 - accuracy: 0.4694 - macro_f1: 0.1732 - val_loss: 0.1486 - val_accuracy: 0.5140 - val_macro_f1: 0.1834 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0831 - accuracy: 0.4777 - macro_f1: 0.1829 - val_loss: 0.1678 - val_accuracy: 0.3551 - val_macro_f1: 0.1285 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0811 - accuracy: 0.4707 - macro_f1: 0.1861 - val_loss: 0.1917 - val_accuracy: 0.5121 - val_macro_f1: 0.1613 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0778 - accuracy: 0.4817 - macro_f1: 0.2111 - val_loss: 0.2446 - val_accuracy: 0.1263 - val_macro_f1: 0.0802 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0728 - accuracy: 0.4934 - macro_f1: 0.2308 - val_loss: 0.1729 - val_accuracy: 0.3751 - val_macro_f1: 0.1667 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0713 - accuracy: 0.5077 - macro_f1: 0.2412 - val_loss: 0.1585 - val_accuracy: 0.3961 - val_macro_f1: 0.1645 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0626 - accuracy: 0.5385 - macro_f1: 0.2696 - val_loss: 0.1184 - val_accuracy: 0.5531 - val_macro_f1: 0.2544 - lr: 1.0000e-04\n",
      "Epoch 11/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0583 - accuracy: 0.5467 - macro_f1: 0.2953 - val_loss: 0.1167 - val_accuracy: 0.5559 - val_macro_f1: 0.2734 - lr: 1.0000e-04\n",
      "Epoch 12/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0561 - accuracy: 0.5580 - macro_f1: 0.3090 - val_loss: 0.1166 - val_accuracy: 0.5494 - val_macro_f1: 0.2833 - lr: 1.0000e-04\n",
      "Epoch 13/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0547 - accuracy: 0.5554 - macro_f1: 0.3171 - val_loss: 0.1143 - val_accuracy: 0.5629 - val_macro_f1: 0.2820 - lr: 1.0000e-04\n",
      "Epoch 14/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0531 - accuracy: 0.5581 - macro_f1: 0.3258 - val_loss: 0.1146 - val_accuracy: 0.5615 - val_macro_f1: 0.2866 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0514 - accuracy: 0.5691 - macro_f1: 0.3357 - val_loss: 0.1166 - val_accuracy: 0.5573 - val_macro_f1: 0.2922 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0501 - accuracy: 0.5722 - macro_f1: 0.3408 - val_loss: 0.1120 - val_accuracy: 0.5713 - val_macro_f1: 0.3001 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0488 - accuracy: 0.5812 - macro_f1: 0.3516 - val_loss: 0.1122 - val_accuracy: 0.5778 - val_macro_f1: 0.3055 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0475 - accuracy: 0.5866 - macro_f1: 0.3606 - val_loss: 0.1134 - val_accuracy: 0.5704 - val_macro_f1: 0.3037 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0461 - accuracy: 0.5887 - macro_f1: 0.3637 - val_loss: 0.1130 - val_accuracy: 0.5732 - val_macro_f1: 0.3085 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0443 - accuracy: 0.5963 - macro_f1: 0.3746 - val_loss: 0.1139 - val_accuracy: 0.5806 - val_macro_f1: 0.3023 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0428 - accuracy: 0.6013 - macro_f1: 0.3855 - val_loss: 0.1180 - val_accuracy: 0.5499 - val_macro_f1: 0.3122 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0401 - accuracy: 0.6064 - macro_f1: 0.3940 - val_loss: 0.1131 - val_accuracy: 0.5750 - val_macro_f1: 0.3154 - lr: 1.0000e-05\n",
      "Epoch 23/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0393 - accuracy: 0.6152 - macro_f1: 0.4011 - val_loss: 0.1122 - val_accuracy: 0.5825 - val_macro_f1: 0.3187 - lr: 1.0000e-05\n",
      "Epoch 24/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0388 - accuracy: 0.6164 - macro_f1: 0.4052 - val_loss: 0.1127 - val_accuracy: 0.5829 - val_macro_f1: 0.3177 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0385 - accuracy: 0.6204 - macro_f1: 0.4089 - val_loss: 0.1124 - val_accuracy: 0.5811 - val_macro_f1: 0.3164 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x73dbc61b7d90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_sub_model = create_resnet_model(input_shape, num_classes_sub)\n",
    "train_model(resnet_sub_model, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "267/267 [==============================] - 13s 20ms/step - loss: 0.1335 - accuracy: 0.2333 - macro_f1: 0.0649 - val_loss: 0.1869 - val_accuracy: 0.2773 - val_macro_f1: 0.0707 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0894 - accuracy: 0.4011 - macro_f1: 0.1432 - val_loss: 0.1557 - val_accuracy: 0.4357 - val_macro_f1: 0.1488 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0701 - accuracy: 0.4798 - macro_f1: 0.2268 - val_loss: 0.1522 - val_accuracy: 0.4543 - val_macro_f1: 0.1872 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0587 - accuracy: 0.5259 - macro_f1: 0.2836 - val_loss: 0.1545 - val_accuracy: 0.4278 - val_macro_f1: 0.1870 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0489 - accuracy: 0.5568 - macro_f1: 0.3374 - val_loss: 0.1516 - val_accuracy: 0.5037 - val_macro_f1: 0.2110 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0433 - accuracy: 0.5870 - macro_f1: 0.3787 - val_loss: 0.1547 - val_accuracy: 0.4818 - val_macro_f1: 0.2275 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0377 - accuracy: 0.6145 - macro_f1: 0.4094 - val_loss: 0.1472 - val_accuracy: 0.5284 - val_macro_f1: 0.2131 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0342 - accuracy: 0.6213 - macro_f1: 0.4374 - val_loss: 0.1476 - val_accuracy: 0.5447 - val_macro_f1: 0.2437 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0304 - accuracy: 0.6483 - macro_f1: 0.4640 - val_loss: 0.1577 - val_accuracy: 0.5051 - val_macro_f1: 0.2365 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0268 - accuracy: 0.6679 - macro_f1: 0.4866 - val_loss: 0.1620 - val_accuracy: 0.5112 - val_macro_f1: 0.2333 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0241 - accuracy: 0.6821 - macro_f1: 0.5074 - val_loss: 0.1630 - val_accuracy: 0.5298 - val_macro_f1: 0.2370 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0230 - accuracy: 0.6864 - macro_f1: 0.5213 - val_loss: 0.1729 - val_accuracy: 0.5121 - val_macro_f1: 0.2505 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0193 - accuracy: 0.7166 - macro_f1: 0.5422 - val_loss: 0.1639 - val_accuracy: 0.5648 - val_macro_f1: 0.2586 - lr: 1.0000e-04\n",
      "Epoch 14/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0155 - accuracy: 0.7324 - macro_f1: 0.5754 - val_loss: 0.1667 - val_accuracy: 0.5610 - val_macro_f1: 0.2593 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0138 - accuracy: 0.7444 - macro_f1: 0.5898 - val_loss: 0.1701 - val_accuracy: 0.5606 - val_macro_f1: 0.2612 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0127 - accuracy: 0.7536 - macro_f1: 0.5964 - val_loss: 0.1726 - val_accuracy: 0.5555 - val_macro_f1: 0.2631 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0120 - accuracy: 0.7586 - macro_f1: 0.6087 - val_loss: 0.1739 - val_accuracy: 0.5666 - val_macro_f1: 0.2631 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x73db45152260>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_sub_model = create_vit_model(input_shape, num_classes_sub)\n",
    "train_model(vit_sub_model, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, classes):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_threshold = (y_pred >= 0.5).astype(int)\n",
    "    report = classification_report(y_test, y_pred_threshold, target_names=classes, zero_division=0, output_dict=True)\n",
    "    print(classification_report(y_test, y_pred_threshold, target_names=classes, zero_division=0))\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Superdiagnostic Classification Report:\n",
      "68/68 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.84      0.68      0.75       496\n",
      "         HYP       0.56      0.65      0.60       262\n",
      "          MI       0.84      0.61      0.71       550\n",
      "        NORM       0.83      0.88      0.86       963\n",
      "        STTC       0.80      0.71      0.75       521\n",
      "\n",
      "   micro avg       0.80      0.74      0.77      2792\n",
      "   macro avg       0.77      0.71      0.73      2792\n",
      "weighted avg       0.80      0.74      0.76      2792\n",
      " samples avg       0.77      0.76      0.75      2792\n",
      "\n",
      "ResNet Superdiagnostic Classification Report:\n",
      "68/68 [==============================] - 1s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.81      0.69      0.75       496\n",
      "         HYP       0.72      0.50      0.59       262\n",
      "          MI       0.72      0.77      0.74       550\n",
      "        NORM       0.87      0.82      0.84       963\n",
      "        STTC       0.72      0.78      0.75       521\n",
      "\n",
      "   micro avg       0.78      0.75      0.77      2792\n",
      "   macro avg       0.77      0.71      0.73      2792\n",
      "weighted avg       0.79      0.75      0.76      2792\n",
      " samples avg       0.77      0.77      0.75      2792\n",
      "\n",
      "ViT Superdiagnostic Classification Report:\n",
      "68/68 [==============================] - 1s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.75      0.63      0.69       496\n",
      "         HYP       0.68      0.43      0.53       262\n",
      "          MI       0.76      0.54      0.63       550\n",
      "        NORM       0.78      0.88      0.83       963\n",
      "        STTC       0.73      0.66      0.69       521\n",
      "\n",
      "   micro avg       0.76      0.68      0.72      2792\n",
      "   macro avg       0.74      0.63      0.67      2792\n",
      "weighted avg       0.75      0.68      0.71      2792\n",
      " samples avg       0.74      0.72      0.71      2792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN Superdiagnostic Classification Report:\")\n",
    "cnn_super_report = evaluate_model(cnn_super_model, X_test, y_test_super, classes_super)\n",
    "\n",
    "print(\"ResNet Superdiagnostic Classification Report:\")\n",
    "resnet_super_report = evaluate_model(resnet_super_model, X_test, y_test_super, classes_super)\n",
    "\n",
    "print(\"ViT Superdiagnostic Classification Report:\")\n",
    "vit_super_report = evaluate_model(vit_super_model, X_test, y_test_super, classes_super)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Subdiagnostic Classification Report:\n",
      "68/68 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.88      0.53      0.66       306\n",
      "       CLBBB       0.91      0.91      0.91        54\n",
      "       CRBBB       0.79      0.91      0.84        54\n",
      "       ILBBB       0.12      0.12      0.12         8\n",
      "         IMI       0.79      0.48      0.60       327\n",
      "       IRBBB       0.56      0.68      0.62       112\n",
      "        ISCA       0.54      0.16      0.25        93\n",
      "        ISCI       0.44      0.30      0.36        40\n",
      "        ISC_       0.72      0.47      0.57       128\n",
      "        IVCD       0.19      0.06      0.09        79\n",
      "   LAFB/LPFB       0.80      0.64      0.71       179\n",
      "     LAO/LAE       0.00      0.00      0.00        42\n",
      "         LMI       0.30      0.15      0.20        20\n",
      "         LVH       0.75      0.53      0.62       214\n",
      "        NORM       0.88      0.76      0.81       963\n",
      "        NST_       0.32      0.16      0.21        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.57      0.40      0.47        10\n",
      "         RVH       1.00      0.08      0.15        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.52      0.38      0.44       222\n",
      "         WPW       0.83      0.62      0.71         8\n",
      "        _AVB       0.53      0.21      0.30        82\n",
      "\n",
      "   micro avg       0.76      0.55      0.64      3034\n",
      "   macro avg       0.54      0.37      0.42      3034\n",
      "weighted avg       0.73      0.55      0.62      3034\n",
      " samples avg       0.62      0.59      0.59      3034\n",
      "\n",
      "ResNet Subdiagnostic Classification Report:\n",
      "68/68 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.77      0.40      0.52       306\n",
      "       CLBBB       0.96      0.91      0.93        54\n",
      "       CRBBB       0.80      0.94      0.86        54\n",
      "       ILBBB       0.11      0.12      0.12         8\n",
      "         IMI       0.71      0.43      0.53       327\n",
      "       IRBBB       0.47      0.68      0.55       112\n",
      "        ISCA       0.33      0.18      0.23        93\n",
      "        ISCI       0.50      0.35      0.41        40\n",
      "        ISC_       0.75      0.52      0.61       128\n",
      "        IVCD       0.14      0.03      0.04        79\n",
      "   LAFB/LPFB       0.80      0.73      0.76       179\n",
      "     LAO/LAE       0.00      0.00      0.00        42\n",
      "         LMI       0.08      0.05      0.06        20\n",
      "         LVH       0.73      0.52      0.60       214\n",
      "        NORM       0.87      0.71      0.78       963\n",
      "        NST_       0.24      0.18      0.21        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.40      0.40      0.40        10\n",
      "         RVH       0.17      0.08      0.11        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.51      0.35      0.41       222\n",
      "         WPW       1.00      0.50      0.67         8\n",
      "        _AVB       0.56      0.28      0.37        82\n",
      "\n",
      "   micro avg       0.72      0.52      0.60      3034\n",
      "   macro avg       0.47      0.36      0.40      3034\n",
      "weighted avg       0.70      0.52      0.59      3034\n",
      " samples avg       0.59      0.56      0.56      3034\n",
      "\n",
      "ViT Subdiagnostic Classification Report:\n",
      "68/68 [==============================] - 1s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.70      0.42      0.53       306\n",
      "       CLBBB       0.88      0.85      0.87        54\n",
      "       CRBBB       0.86      0.81      0.84        54\n",
      "       ILBBB       0.00      0.00      0.00         8\n",
      "         IMI       0.65      0.46      0.54       327\n",
      "       IRBBB       0.56      0.27      0.36       112\n",
      "        ISCA       0.38      0.05      0.09        93\n",
      "        ISCI       0.20      0.03      0.04        40\n",
      "        ISC_       0.63      0.38      0.48       128\n",
      "        IVCD       0.06      0.06      0.06        79\n",
      "   LAFB/LPFB       0.83      0.36      0.50       179\n",
      "     LAO/LAE       0.50      0.02      0.05        42\n",
      "         LMI       0.25      0.05      0.08        20\n",
      "         LVH       0.61      0.39      0.48       214\n",
      "        NORM       0.85      0.62      0.72       963\n",
      "        NST_       0.10      0.12      0.11        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.00      0.00      0.00        10\n",
      "         RVH       0.14      0.08      0.11        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.39      0.25      0.31       222\n",
      "         WPW       1.00      0.12      0.22         8\n",
      "        _AVB       0.13      0.04      0.06        82\n",
      "\n",
      "   micro avg       0.66      0.42      0.51      3034\n",
      "   macro avg       0.42      0.23      0.28      3034\n",
      "weighted avg       0.64      0.42      0.50      3034\n",
      " samples avg       0.48      0.46      0.45      3034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN Subdiagnostic Classification Report:\")\n",
    "cnn_sub_report = evaluate_model(cnn_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"ResNet Subdiagnostic Classification Report:\")\n",
    "resnet_sub_report = evaluate_model(resnet_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"ViT Subdiagnostic Classification Report:\")\n",
    "vit_sub_report = evaluate_model(vit_sub_model, X_test, y_test_sub, classes_sub)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
